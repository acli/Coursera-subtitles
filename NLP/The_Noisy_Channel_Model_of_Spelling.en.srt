1
00:00:01,013 --> 00:00:06,040
Let's introduce the noisy channel model of
spelling. The intuition of the noisy

2
00:00:06,040 --> 00:00:10,042
channel, and it comes up throughout
natural language processing, is that we

3
00:00:10,042 --> 00:00:14,055
have some original signal. Let's say it's
a word. And we imagine that it goes

4
00:00:14,055 --> 00:00:18,062
through some channel. And the idea was
originally invented for speech, where

5
00:00:18,062 --> 00:00:22,053
there were, you know, if you talk into a
tube or you go over some kind of

6
00:00:22,053 --> 00:00:26,093
telecommunications line, and the word is
distorted. And so what comes out from the

7
00:00:26,093 --> 00:00:31,017
original word, is some noisy word. And
we've represented that here with a weird

8
00:00:31,017 --> 00:00:36,010
font. But. In the spelling case we imagine
that, oh somebody mistyped the word. So

9
00:00:36,010 --> 00:00:41,005
the channel is the typewriter or the
person typing or the keyboard, and at the

10
00:00:41,005 --> 00:00:45,075
end, you've got a misspelled version of
the word. And our goal in the noisy

11
00:00:45,075 --> 00:00:50,077
channel is to take that output, of that
noisy process, and by modeling how this

12
00:00:50,077 --> 00:00:55,028
channel works, we built a model,
[inaudible] model of the channel. We can

13
00:00:55,028 --> 00:01:00,042
run all possible original words through
that channel and see which one looks the

14
00:01:00,042 --> 00:01:05,035
most like the noisy word. So the decoder
will take. A bunch of hypotheses. For each

15
00:01:05,035 --> 00:01:09,039
one, run it through the channel, just
running hypothesis two through the

16
00:01:09,039 --> 00:01:13,099
channel, run hypothesis three through the
channel, and we see which word looks the

17
00:01:13,099 --> 00:01:18,042
most like this noisy word, and we pick
that as the original hypothesis for the

18
00:01:18,042 --> 00:01:22,048
word that started out. So let's look at
that. First we'll introduce some

19
00:01:22,048 --> 00:01:27,087
probability and then we'll look at some
examples. The noisy channel is a

20
00:01:27,087 --> 00:01:33,095
probabilistic model. Our goal given an
observation x of some misspelling. Some

21
00:01:33,095 --> 00:01:39,082
word we've seen, some surface thing we've
seen, some observation x. We'd like to

22
00:01:39,082 --> 00:01:45,029
find w the correct word. And we're gonna
model that. Probabilistically, by saying

23
00:01:45,029 --> 00:01:49,092
we're looking. The best word, the word
that we'd like to replace our misspelling

24
00:01:49,092 --> 00:01:54,025
with is that word out of the vocabulary
that maximizes a probability. What

25
00:01:54,025 --> 00:01:58,098
probability? The probability of the word
given the misspelling. So what word, given

26
00:01:58,098 --> 00:02:04,073
that we've seen some misspelling. What's
the most likely word? The most probable

27
00:02:04,073 --> 00:02:10,030
posterior probable word, given that
misspelling. And we're gonna use

28
00:02:10,030 --> 00:02:16,061
[inaudible] rule, to re-, to replace that
probability. So, the probability of W

29
00:02:16,061 --> 00:02:23,042
given X. We're gonna replace that with P
of X, given W. P of W over P of X. And so,

30
00:02:23,042 --> 00:02:29,032
we, we, we can also eliminate the
denominator. So whatever word maximizes

31
00:02:29,032 --> 00:02:34,031
this equation. We'll also maximize this
equation. We're asking, given a

32
00:02:34,031 --> 00:02:39,040
misspelling X, what's the most likely
word? And since the formula for that

33
00:02:39,040 --> 00:02:44,055
probability includes the probability of
the word, the misspelling X. We're

34
00:02:44,055 --> 00:02:50,099
including that probability in every W that
we're considering. So if sum W, say, W

35
00:02:50,099 --> 00:02:57,035
hypothesis one, has a greater probability
than hypothesis two. By this equation,

36
00:02:57,035 --> 00:03:03,095
it'll also have a greater probability by
this equation, because X is a constant. X

37
00:03:03,095 --> 00:03:10,063
is the misspelling that we're trying to
decide if W1 or W2 is a better hypothesis

38
00:03:10,063 --> 00:03:18,016
for it. So that means. That the noisy
channel model. Comes down to maximizing

39
00:03:18,016 --> 00:03:29,037
the product of two factors. The
likelihood. And the prior. And we

40
00:03:29,037 --> 00:03:35,049
generally call this term the language
model. And you've seen language models

41
00:03:35,049 --> 00:03:40,057
before. That's the probability of the
error, probability of, excuse me, that's

42
00:03:40,057 --> 00:03:45,080
the probability of the correct word, w.
And this likelihood term, we often call

43
00:03:45,080 --> 00:03:55,008
this the channel model. Where sometimes
the error model. So we've got two factors.

44
00:03:55,008 --> 00:04:00,060
The language model and the channel model,
and the intuition is. The language model

45
00:04:00,060 --> 00:04:05,095
tells us how likely would this word be to
be a word perhaps in this context, perhaps

46
00:04:05,095 --> 00:04:10,092
by itself. The channel model says, well,
if it was that word, how likely would it

47
00:04:10,092 --> 00:04:15,096
be to generate this exact error? So the
channel model was sort of modeling that

48
00:04:15,096 --> 00:04:20,090
noisy channel that turns the correct word
into the misspelling. Now this noisy

49
00:04:20,090 --> 00:04:25,096
channel model for spelling was proposed
around 1990. Independently of two separate

50
00:04:25,096 --> 00:04:30,096
laboratories. And the use of speech
recognition models like noisy channel came

51
00:04:30,096 --> 00:04:35,050
into natural language processing right
around then. Mainly, although not

52
00:04:35,050 --> 00:04:40,093
exclusively, because of the work at these
two labs at IBM, and at, AT and T Bell

53
00:04:40,093 --> 00:04:46,056
Labs. And so the examples we're gonna take
for the rest of this example come from,

54
00:04:46,077 --> 00:04:52,034
these two, important early papers by
[inaudible] and by Khernigan [inaudible].

55
00:04:52,034 --> 00:04:57,065
So let's look at an example. Here's a
misspelling. The word A-C-R-E-S-S. So

56
00:04:57,065 --> 00:05:06,064
think for yourself for a second what this
could mean. First, we're gonna start with

57
00:05:06,064 --> 00:05:11,050
generating candidates. What are the
possible candidate words to replace this

58
00:05:11,050 --> 00:05:15,098
word? And we can think of a, at least a
couple of obvious ways to do this, one is,

59
00:05:15,098 --> 00:05:20,037
we're gonna pick words that have similar
spelling. So words that, that are, have

60
00:05:20,037 --> 00:05:24,054
similar spelling might naturally be
mistaken for, for the correct word. And

61
00:05:24,054 --> 00:05:29,049
we're gonna. Operationalize similar
spelling as having a small edit distance

62
00:05:29,049 --> 00:05:33,066
to the error. Or we could pick words with
similar pronunciation and there we're

63
00:05:33,066 --> 00:05:37,032
gonna pick a word with a small edit
distance of the pronunciation to the

64
00:05:37,032 --> 00:05:41,013
error. And we're gonna, for the rest of
this example I'm gonna pick the first

65
00:05:41,013 --> 00:05:45,004
approach. So, we're gonna pick words that
have similar spelling as our possible

66
00:05:45,004 --> 00:05:49,029
candidates. How do I operationalize
similar spelling? Well, we've seen edit

67
00:05:49,029 --> 00:05:53,087
distance before. And remember, with edit
distance we talked about the distance

68
00:05:53,087 --> 00:05:58,082
between two strings, the minimal number of
edits that turns one string into another,

69
00:05:58,082 --> 00:06:03,052
where we define an edit as an insertion, a
deletion, or a substitution, so any of

70
00:06:03,052 --> 00:06:08,047
these three. For spell correction, we're
gonna want to add a fourth possible edit

71
00:06:08,047 --> 00:06:12,082
operation, transposition, because in
practice for spelling errors, we often

72
00:06:12,082 --> 00:06:17,041
transpose two letters. And that version of
edit distance is now called Damero

73
00:06:17,041 --> 00:06:22,091
Levenstein edit distance. And it can be
computed, again by various dynamic

74
00:06:22,091 --> 00:06:31,082
programming approaches. So let's look at
the candidates that are words within a

75
00:06:31,082 --> 00:06:37,033
distance one of our misspelling
A-C-R-E-S-S. So here's our error.

76
00:06:38,012 --> 00:06:44,043
A-c-r-e-s-s and here is different possible
candidates. So here's a candidate actress.

77
00:06:44,043 --> 00:06:50,006
How is actress turned into across? Well,
the T turns into nothing, so a T was

78
00:06:50,006 --> 00:06:55,084
deleted. So we have a deletion of a T. So
a deletion of a T turns actress into

79
00:06:55,084 --> 00:07:01,056
across. Here, the proposed candidate is
the word cress. The kind of vegetable. So,

80
00:07:01,056 --> 00:07:07,019
here crest, to turn crest into aquarist we
have to insert add, insert an a. So, here

81
00:07:07,019 --> 00:07:12,048
we had a deletion, here we had an
insertion. How about caress? Caress is to

82
00:07:12,048 --> 00:07:18,011
turn caress into aquarist we turn a ca
into the ac. We have a transposition of ca

83
00:07:18,011 --> 00:07:24,069
and ac. The word could've been access.
Here we have a substitution: the c turned

84
00:07:24,069 --> 00:07:30,075
into an r. Or another substitution. The
word could've been across, and the o

85
00:07:30,075 --> 00:07:37,020
turned into an e. Or an s could've been
inserted, to turn acres into, into acres?;

86
00:07:37,020 --> 00:07:43,041
but the s could've been inserted either
here. Or here, so there's two different

87
00:07:43,041 --> 00:07:48,031
ways where this source word could have
turned into this error form. So we'll put

88
00:07:48,031 --> 00:07:53,014
two rows down for both of these possible
insertion locations, positions. So I've

89
00:07:53,014 --> 00:07:58,003
just shown you candidates that are within
ETA distance of one. It turns out that,

90
00:07:58,003 --> 00:08:02,086
that 80 percent of, of spelling errors are
within ETA distance of one. And almost all

91
00:08:02,086 --> 00:08:07,088
errors are within ETA distance of two. So
most algorithms either consider just ETA

92
00:08:07,088 --> 00:08:13,022
distance one or ETA distance two possible
candidates. In practice we also want to

93
00:08:13,022 --> 00:08:19,010
allow, not just insertion and substitution
of letters, but also of spaces or hyphens.

94
00:08:19,010 --> 00:08:24,044
So for example, if the user types this
idea, we'd like to realize that, there

95
00:08:24,044 --> 00:08:30,019
should be insertion of a space, or that
the original space was in fact deleted to

96
00:08:30,019 --> 00:08:35,018
produce this error form. Or here, the
original dash in the word in-law was

97
00:08:35,018 --> 00:08:41,010
deleted this error form, in-law. We've
seen candidate generation, now we're ready

98
00:08:41,010 --> 00:08:45,078
to talk about how to rank the candidates.
And remember, there are two factors. We

99
00:08:45,078 --> 00:08:50,050
have the language model and the channel
model. Now, the language model, we can use

100
00:08:50,050 --> 00:08:55,034
any of the language modeling algorithms
we've already learned. We can use unigrams

101
00:08:55,034 --> 00:09:00,000
and bigrams and trigrams. We can use any
kind of back off algorithm we wanna use,

102
00:09:00,000 --> 00:09:04,058
or smoothing algorithm we wanna use, in
practice for very, very large scale web

103
00:09:04,058 --> 00:09:08,092
scale correction, we're gonna use, as
usual, for web scale things, we're gonna

104
00:09:08,092 --> 00:09:13,093
use stupid back off. But we might wanna
use smarter algorithms for smaller kinds

105
00:09:13,093 --> 00:09:21,078
of tasks. [sound] So let's look at an
example of a language model. Here I picked

106
00:09:21,078 --> 00:09:27,038
just a very simple unigram. And in this
case we've computed the unigram from the

107
00:09:27,038 --> 00:09:32,058
corpus of contemporary English, one of the
many possible corpora. And here's some

108
00:09:32,058 --> 00:09:37,009
counts. Here's counts of the different
possible candidates actress, cress,

109
00:09:37,009 --> 00:09:42,041
caress, and so on. Here's their frequency
and normal life by the total number of

110
00:09:42,041 --> 00:09:47,017
words we get a probability of the total
number of words. We get a normalizing

111
00:09:47,017 --> 00:09:51,093
discount by the total count, we get
probabilities. So here's the probabilities

112
00:09:51,093 --> 00:09:57,084
of, of words assigned by unigram language
model. How about computing the channel

113
00:09:57,084 --> 00:10:03,012
model probability. Remember, the channel
model's also called the error model or the

114
00:10:03,012 --> 00:10:09,052
edit probability. And we're gonna take a,
simplifying assumption made by, Kernighan,

115
00:10:09,052 --> 00:10:15,044
Church, and Gale in 1990, when they first
proposed the use of the noisy channel

116
00:10:15,044 --> 00:10:21,027
models. So, let's first see how to do
that. Let's assume that a misspelled word

117
00:10:21,027 --> 00:10:27,041
X has a set of letters, X1 through XM. And
the correct word, W, has a set of letters,

118
00:10:27,041 --> 00:10:33,066
let's call them W1 through WN. Now the
probability of the edit X, given W. Is

119
00:10:33,066 --> 00:10:37,064
gonna be some set of deletions or
insertions or substitutions or

120
00:10:37,064 --> 00:10:44,018
transpositions, some set of edits. The way
we're gonna model that is we're gonna

121
00:10:44,018 --> 00:10:51,094
create a confusion matrix. And a confusion
matrix says for any given letter pair of

122
00:10:51,094 --> 00:10:58,078
letters, how likely is a particular edit
to happen. So for example, for the pair of

123
00:10:58,078 --> 00:11:06,042
letters X, Y. We want to know how often xy
is typed as x. Meaning, how often is a y

124
00:11:06,042 --> 00:11:12,052
delete when there's a x right before it.
We're gonna also keep a count of for

125
00:11:12,052 --> 00:11:18,040
insertion probabilities how often was an X
typed as XY. So how often is Y inserted

126
00:11:18,040 --> 00:11:23,072
after X. So Y deleted after X, Y inserted
after X. Or we'll keep a count for

127
00:11:23,072 --> 00:11:29,046
substitutions. How often is X typed as Y?
So we meant to type X, we typed Y. That's

128
00:11:29,046 --> 00:11:35,020
an XY substitution. Or a transposition,
how often was XY typed as YX? So these are

129
00:11:35,020 --> 00:11:40,081
just counts. We'll keep a matrix of these
counts for every X and for every Y. I

130
00:11:40,081 --> 00:11:48,022
noticed what we've done implicitly is
we've conditioned our insertion. And our

131
00:11:48,022 --> 00:11:52,056
deletion on the previous character. So
whether Y is deleted is conditioned on X.

132
00:11:52,056 --> 00:11:57,001
We could have conditioned twelve from the
condition of the next character or the

133
00:11:57,001 --> 00:12:01,047
character five to the left or some other
thing, but we generally condition on the

134
00:12:01,047 --> 00:12:06,084
previous character. So here's an example
of a confusion matrix for spelling errors.

135
00:12:06,084 --> 00:12:12,039
The font is a little small, but just to
give you a basic idea. Here's this is a

136
00:12:12,039 --> 00:12:17,054
substitution matrix that I took from
Kernigan et al. So here's the letter e,

137
00:12:17,054 --> 00:12:23,003
and it's very likely in their, in their
data 388 times to be substituted with an

138
00:12:23,003 --> 00:12:27,083
a. So, you meant to type e, you
incorrectly typed an a. Or you might have

139
00:12:27,083 --> 00:12:33,011
typed an I, or you might have typed an o.
So vowels are very likely to be mist,

140
00:12:33,032 --> 00:12:38,079
mistaken for each other. Or similarly. The
letter m very often gets mistyped as an n.

141
00:12:38,079 --> 00:12:43,083
So, a very high probability of m and n
being substituted for each other. They're

142
00:12:43,083 --> 00:12:48,093
next to each other on the keyboard. They
sound alike. Lots of reasons for them to

143
00:12:48,093 --> 00:12:53,072
be substituted. So, here's our set of
confusion matrices, and we just compute

144
00:12:53,072 --> 00:12:58,063
four of them. One for substitution. One,
substitution. One for insertion. One for

145
00:12:58,063 --> 00:13:04,057
deletion. And one for transposition. Now
I've shown you this table comes from

146
00:13:04,057 --> 00:13:11,023
[inaudible]. But you could also generate
the table yourself. So for example Peter

147
00:13:11,023 --> 00:13:20,056
Norvick post on his website a lovely list
of errors. So these are errors taken from

148
00:13:20,056 --> 00:13:27,066
Wikipedia and other places, that, he talks
about on his website. And from a set of

149
00:13:27,066 --> 00:13:34,016
errors like this. So, here, misspellings
of adaptable as, as, adaptable or,

150
00:13:34,042 --> 00:13:41,012
immature with only one M, and so on. So
various kinds of likely misspellings. And

151
00:13:41,012 --> 00:13:47,011
from this list of errors we can get a list
of counts for every possible single error,

152
00:13:47,011 --> 00:13:52,082
single edit error of how often it happens
and from that we can build. So we build

153
00:13:52,082 --> 00:13:58,060
our little confusion matrix and then from
the confusion matrix we can generate

154
00:13:58,060 --> 00:14:06,099
probabilities. So. Every time a particular
previous letter happens. We, we look up in

155
00:14:06,099 --> 00:14:12,045
our insertion may confusion matrix and we
say how often was xi inserted after a

156
00:14:12,045 --> 00:14:18,011
particular letter w sub I minus one and we
divide by the number of times we minus one

157
00:14:18,011 --> 00:14:22,072
occurred and that's gonna be the
probability of a particular insertion.

158
00:14:22,072 --> 00:14:28,030
Happening, in a word. So we can generate
our probability of our surface form by for

159
00:14:28,030 --> 00:14:33,043
each possible single edit error, again
we're assuming a single edit now, so one,

160
00:14:33,043 --> 00:14:38,089
only one of these happens to generate our
candidate. Whichever one it is, we compute

161
00:14:38,089 --> 00:14:44,002
our probability by just normalizing the
count of the deletion or insertion or

162
00:14:44,002 --> 00:14:48,062
substitution or transposition, by the
appropriate count, and generate a

163
00:14:48,062 --> 00:14:59,023
probability. So, this channel model. For
example for a word like actress. Where we,

164
00:14:59,055 --> 00:15:07,098
we generated A-C-R-E-S-S by when we should
have typed a C. Excuse me. When we should

165
00:15:07,098 --> 00:15:14,080
have typed a CT, we typed a C so the word
had a CT in it but the error had only a C.

166
00:15:14,080 --> 00:15:21,062
So what's the probability of deleting a T
following a C? And if we'd normalized the

167
00:15:21,062 --> 00:15:28,027
probabilities in our confusion matrix,
here's the likelihood of this word actress

168
00:15:28,027 --> 00:15:35,007
being realized as the misspelling acres?,
it's.000117. The language model so, here's

169
00:15:35,007 --> 00:15:41,022
the error model or the channel model. And
now we can add in the language model, or

170
00:15:41,022 --> 00:15:46,014
write LM. So we have the channel model.
How likely was CT to be, error fully

171
00:15:46,015 --> 00:15:51,027
turned into C? So T to be deleted. And how
likely is the word actress, anyway? And we

172
00:15:51,027 --> 00:15:56,045
can just multiply these together. And what
we'll do is, because these are very small

173
00:15:56,045 --> 00:16:01,057
numbers, we'll just multiply everything by
ten to the ninth to, to make it readable.

174
00:16:01,057 --> 00:16:07,093
So, so this would be 2.7 times ten to the
minus ninth. But we multiplied everything

175
00:16:07,093 --> 00:16:14,023
by ten to the ninth here. So you can see
that the most likely word here is across.

176
00:16:14,023 --> 00:16:20,011
I, with this particular this particular
channel model, and this particular

177
00:16:20,011 --> 00:16:27,010
language model the most likely word is a
cross. But, actress is also quite likely.

178
00:16:27,010 --> 00:16:31,059
And, and acre seems a reasonably
likelihood. And the word crass, which is

179
00:16:31,059 --> 00:16:36,044
just a very rare word, you can see, has a
very low probability. And has an unusual

180
00:16:36,044 --> 00:16:41,005
error of inserting an A at the beginning.
Makes it a very low probability

181
00:16:41,005 --> 00:16:45,061
correction. So the noisy channel model
like the word across as the possible

182
00:16:45,061 --> 00:16:51,052
replacement. Unfortunately. We can see
from the original sentence, taken from

183
00:16:51,052 --> 00:16:57,046
Kernighan et al's paper, that the original
sentence across is the wrong word. The in

184
00:16:57,065 --> 00:17:02,038
the original sentence is a stellar and
versatile. [inaudible] whose combination

185
00:17:02,038 --> 00:17:06,052
of sass and glamour. And it should be
clear that this word should have been

186
00:17:06,052 --> 00:17:10,082
actress. So it crosses the wrong word. So,
just using a unigram model, the noisy

187
00:17:10,082 --> 00:17:15,040
channel makes a mistake. So let's look at
a bigram model. How well can we do with a

188
00:17:15,040 --> 00:17:19,098
bigram model? So we computed a very simple
bigram model, just using [inaudible], add

189
00:17:19,098 --> 00:17:24,012
one smoothing from the corpus of
contemporary American English. So now, the

190
00:17:24,012 --> 00:17:28,064
probability of actress given versatile.
Just look at these three words, and ignore

191
00:17:28,064 --> 00:17:33,000
the rest for now. Actress, given
versatile. That probability is.00021, and

192
00:17:33,000 --> 00:17:38,045
who is given actress is.00010 so we'll
compute those. And now let's do the same

193
00:17:38,045 --> 00:17:43,076
thing for another candidate, the original
candidate that was preferred by the

194
00:17:43,076 --> 00:17:51,057
unigram model, the word cross. We'll put a
cross here, instead is our hypothesis, and

195
00:17:51,057 --> 00:17:55,073
again we'll compute the probability of a
cross giving versatile times the

196
00:17:55,073 --> 00:18:00,074
probability of who is giving the cross. So
here's those probabilities. And you can

197
00:18:00,074 --> 00:18:05,040
see that the probability of who was given
actress is much higher than the

198
00:18:05,040 --> 00:18:10,030
probability of who was given across.
Actress who is just a likely sequence. And

199
00:18:10,030 --> 00:18:15,058
sure enough, if we multiply these things
out, the probability of versatile actress

200
00:18:15,058 --> 00:18:20,049
who's is a much higher probability than
the prob-, then the sequence versatile,

201
00:18:20,049 --> 00:18:24,083
across whose. So a much higher
probability. So the noisy channel model

202
00:18:24,083 --> 00:18:31,000
with a bigram language model correctly
picks the, correction actress. How are we

203
00:18:31,000 --> 00:18:37,094
gonna evaluate the these noisy channel and
other kinds of models? There are lots of

204
00:18:37,094 --> 00:18:44,035
good spelling error test sets. Wikipedia
has a list of common English misspellings.

205
00:18:44,057 --> 00:18:50,091
There's a filtered version of that at A
spell. There's a spelling error corpus at

206
00:18:50,091 --> 00:19:00,038
Birkbeck. Let's look at the Wikipedia
list. So there's Wikipedia's list of

207
00:19:00,038 --> 00:19:06,024
common English misspellings. And, I've
shown you here on this slide some various

208
00:19:06,024 --> 00:19:11,053
other possible lists that you can go look
at on your own. So from these lists of

209
00:19:11,053 --> 00:19:17,063
misspellings you would generate a training
set to train your channel model. A

210
00:19:17,063 --> 00:19:23,095
development set to test out your model and
then a final test set to see how well your

211
00:19:23,095 --> 00:19:30,005
model works. So that's the noisy channel
model of spelling applied to, to non-real
